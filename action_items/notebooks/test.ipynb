{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb45e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
    "from sklearn.metrics import accuracy_score,matthews_corrcoef\n",
    "\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from transformers import (DistilBertTokenizer, BertConfig, AdamW, BertForSequenceClassification,\n",
    "                          DistilBertConfig,\n",
    "                          get_linear_schedule_with_warmup, DistilBertForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f0abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edea2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and specify the GPU as the device, later in training loop we will load data into device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#n_gpu = torch.cuda.device_count()\n",
    "#torch.cuda.get_device_name(0)\n",
    "\n",
    "SEED = 19\n",
    "MAX_LEN = 128\n",
    "batch_size = 1\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711e08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b73ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        try:\n",
    "            self.texts = [tokenizer(text, \n",
    "                                   padding='max_length', max_length = MAX_LEN, truncation=True,\n",
    "                                    return_tensors=\"pt\") for text in df[\"text\"]]\n",
    "\n",
    "        except:\n",
    "        ###  ---- ONLY FOR TESTING -----\n",
    "\n",
    "            self.texts = [tokenizer(df, \n",
    "                                   padding='max_length', max_length = MAX_LEN, truncation=True,\n",
    "                                    return_tensors=\"pt\")]\n",
    "\n",
    "    # def classes(self):\n",
    "    #     return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    # def get_batch_labels(self, idx):\n",
    "    #     # Fetch a batch of labels\n",
    "    #     return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        # batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts#, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b18be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "        \n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=768)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        pooled_output = self.bert(input_ids= input_id, attention_mask=mask).logits\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "#         final_layer_1 = self.sigmoid(final_layer)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b940dd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55765125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"testing.csv\")\n",
    "# text = df[\"Sub-issue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b05d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fab6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class predict_empathy:\n",
    "\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.model = BertClassifier()\n",
    "            checkpoint = torch.load('distil_action_item.pth', map_location='cpu')\n",
    "            # print(checkpoint['model_state_dict'])\n",
    "            \n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        except Exception as e:\n",
    "            print(\"cannnot initilize model\")\n",
    "            raise e\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        try:\n",
    "            predictions = []\n",
    "            probability = []\n",
    "            df_test = test_data\n",
    "#             print(type(test_data))\n",
    "            if os.path.exists(test_data):\n",
    "                df_test = pd.read_csv(test_data)\n",
    "#                 df_test = df_test[:1000][\"Sub-issue\"].dropna()\n",
    "#                 print(df_test)\n",
    "#             ##test_ot = df_test.at[df_test.index[1],'response_post']\n",
    "\n",
    "            test = Dataset(df_test)\n",
    "\n",
    "            test_dataloader = torch.utils.data.DataLoader(\n",
    "                test, batch_size=batch_size)\n",
    "\n",
    "            use_cuda = torch.cuda.is_available()\n",
    "            device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#             print(device)\n",
    "            if use_cuda:\n",
    "\n",
    "                self.model = self.model.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for test_input in test_dataloader:\n",
    "\n",
    "                    # test_label = test_label.to(device)\n",
    "                    mask = test_input['attention_mask'].to(device)\n",
    "                    input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = self.model(input_id, mask)\n",
    "                    probability.append(str(output))\n",
    "\n",
    "#                     print(\"print output 1>>>>\",output)\n",
    "                    output1 = output.argmax(dim=1)\n",
    "#                     print(\"print output 2>>>>\",output)\n",
    "\n",
    "                    if output1 == 1:\n",
    "                        # print(1)\n",
    "                        output1 = 1\n",
    "                \n",
    "#                         if output[0][1]>4:\n",
    "#                             output1 = 1#'Empathy'\n",
    "#                         else:\n",
    "#                             # print(0)\n",
    "#                             output1 = 0#'Not Empathy'\n",
    "                    else:\n",
    "                        # print(0)\n",
    "                        output1 = 0#'Not Empathy'\n",
    "                    predictions.append(output1)\n",
    "            if os.path.exists(test_data):\n",
    "                df_test['pred'] = predictions\n",
    "                df_test['probability'] = probability\n",
    "#                 df_test_2 = pd.DataFrame({\"text\":df_test,\"pred\":predictions,\"prob\":probability})\n",
    "\n",
    "                df_test.to_csv(test_data,index =False)\n",
    "\n",
    "            return predictions,probability\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            raise e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed1eb8",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    input_text = [\"This is your local internet service provider.\",\"How may I help you?\",\"Today?\"\n",
    "                  ,\"I installed your internet service for my new home and its really slow.\"\n",
    "                 ,\"I can send it internet service technician to your home whenever you're free.\"\n",
    "                 ,\"Could you let me know what time works for you?\"\n",
    "                 ,\"I will finish my work by 5 PM so you could send a technician after.\"\n",
    "                 ,\"That, okay?\"\n",
    "                 ,\"I just need to follow up with the technician first.\"\n",
    "                 ,\"I will call you back in an hour to confirm your.\"\n",
    "                 ,\"Appointment.\"\n",
    "                 ,\"Okay\"\n",
    "                 ,\"Thank you for calling.\"\n",
    "                 ,\"Thank you.\"]\n",
    "    pred_obj = predict_empathy()\n",
    "    for i in input_text:\n",
    "        predictions,probability = pred_obj.predict(i)\n",
    "        print(i)\n",
    "        print(probability,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d7027",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    input_text = [\"Please let me know if you want anything else\"]\n",
    "    pred_obj = predict_empathy()\n",
    "    for i in input_text:\n",
    "        predictions,probability = pred_obj.predict(i)\n",
    "        print(i)\n",
    "        print(probability,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4d0d50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pred_obj = predict_empathy()\n",
    "#     output_model = 'action_item.pth'\n",
    "#     test_data = r'D:\\F\\projects\\lakebrains\\nikhil_ai\\data\\empathybalaceddata_test.csv'\n",
    "    test_data = 'testing.csv'\n",
    "    predictions,probability = pred_obj.predict(test_data)\n",
    "#     print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f8098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5c5c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9aa6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test.label\n",
    "actual = test.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28c3bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8534ed56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       420\n",
      "           1       0.99      0.85      0.91       579\n",
      "\n",
      "    accuracy                           0.91       999\n",
      "   macro avg       0.91      0.92      0.91       999\n",
      "weighted avg       0.92      0.91      0.91       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2748e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ct = pd.crosstab(actual, pred)\n",
    "\n",
    "pl = ct.plot(kind=\"pie\",subplots=True, stacked=False, rot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f757625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9281c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457d587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1743383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb4285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
